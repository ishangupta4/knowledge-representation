{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T20:15:39.322993Z",
     "start_time": "2025-11-02T20:15:38.299544Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19742f3970990a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T20:17:28.748241Z",
     "start_time": "2025-11-02T20:17:28.741666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building the Knowledge Graph\n",
    "\n",
    "class AcademicKnowledgeGraph:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.MultiDiGraph()\n",
    "        self.facts = set()  # For storing derived facts\n",
    "\n",
    "    def add_paper(self, paper_id, title, year, topics):\n",
    "        \"\"\"Add a paper node with metadata\"\"\"\n",
    "        self.graph.add_node(\n",
    "            paper_id,\n",
    "            type='paper',\n",
    "            title=title,\n",
    "            year=year,\n",
    "            topics=topics\n",
    "        )\n",
    "\n",
    "        # Add topic relationships\n",
    "        for topic in topics:\n",
    "            if not self.graph.has_node(topic):\n",
    "                self.graph.add_node(topic, type='topic')\n",
    "            self.graph.add_edge(paper_id, topic, relation='has_topic')\n",
    "\n",
    "    def add_author(self, author_id, name, affiliation):\n",
    "        \"\"\"Add an author node\"\"\"\n",
    "        self.graph.add_node(\n",
    "            author_id,\n",
    "            type='author',\n",
    "            name=name,\n",
    "            affiliation=affiliation\n",
    "        )\n",
    "\n",
    "    def add_authorship(self, author_id, paper_id):\n",
    "        \"\"\"Link author to paper\"\"\"\n",
    "        self.graph.add_edge(author_id, paper_id, relation='authored')\n",
    "        self.graph.add_edge(paper_id, author_id, relation='written_by')\n",
    "\n",
    "    def add_citation(self, citing_paper, cited_paper):\n",
    "        \"\"\"Add citation relationship\"\"\"\n",
    "        self.graph.add_edge(citing_paper, cited_paper, relation='cites')\n",
    "        self.graph.add_edge(cited_paper, citing_paper, relation='cited_by')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6663ca7b",
   "metadata": {},
   "source": [
    "#### Keyword Search\n",
    "\n",
    "Query: \"Python programming\"\n",
    "Method: Find documents containing words \"Python\" AND \"programming\"\n",
    "\n",
    "\n",
    "**Problems:**\n",
    "1. **Misses synonyms**: Won't find \"Python coding\" or \"Python development\"\n",
    "2. **Ambiguity**: Finds articles about Python snakes\n",
    "3. **No context**: Can't distinguish \"Python for ML\" from \"Python for web dev\"\n",
    "4. **No relationships**: Can't answer \"Who created Python?\"\n",
    "\n",
    "**This is pattern matching on text—no understanding of meaning.**\n",
    "\n",
    "#### Semantic Search\n",
    "\n",
    "How knowledge-based search works:\n",
    "\n",
    "Query: \"Python programming\"\n",
    "Method: Understand Python is a ProgrammingLanguage\n",
    "        Find related concepts: syntax, libraries, applications\n",
    "        Use relationships: created_by, used_for, related_to\n",
    "\n",
    "**Advantages:**\n",
    "1. **Understands concepts**: Python(Programming Language) ≠ Python(Snake)\n",
    "2. **Uses relationships**: Can infer \"Guido van Rossum created Python\"\n",
    "3. **Handles synonyms**: Knows \"programming\" ≈ \"coding\" ≈ \"development\"\n",
    "4. **Contextual**: Understands Python is used_for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf575ea8c68e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Queries (Graph Traversal)\n",
    "\n",
    "class QueryEngine:\n",
    "    def __init__(self, kg):\n",
    "        self.kg = kg\n",
    "\n",
    "    def get_papers_by_author(self, author_id):\n",
    "        \"\"\"Find all papers by a specific author\"\"\"\n",
    "        papers = []\n",
    "        for neighbor in self.kg.graph.neighbors(author_id):\n",
    "            if self.kg.graph.nodes[neighbor].get('type') == 'paper':\n",
    "                papers.append({\n",
    "                    'id': neighbor,\n",
    "                    'title': self.kg.graph.nodes[neighbor]['title'],\n",
    "                    'year': self.kg.graph.nodes[neighbor]['year']\n",
    "                })\n",
    "        return papers\n",
    "\n",
    "    def find_coauthors(self, author_id):\n",
    "        \"\"\"Find all coauthors of an author\"\"\"\n",
    "        coauthors = set()\n",
    "        # Get papers by this author\n",
    "        for paper in self.kg.graph.neighbors(author_id):\n",
    "            if self.kg.graph.nodes[paper].get('type') == 'paper':\n",
    "                # Get all authors of this paper\n",
    "                for author in self.kg.graph.neighbors(paper):\n",
    "                    if (self.kg.graph.nodes[author].get('type') == 'author'\n",
    "                        and author != author_id):\n",
    "                        coauthors.add(author)\n",
    "        return list(coauthors)\n",
    "\n",
    "    def find_papers_on_topic(self, topic):\n",
    "        \"\"\"Find all papers related to a topic\"\"\"\n",
    "        papers = []\n",
    "        if topic in self.kg.graph:\n",
    "            for paper in self.kg.graph.predecessors(topic):\n",
    "                if self.kg.graph.nodes[paper].get('type') == 'paper':\n",
    "                    papers.append({\n",
    "                        'id': paper,\n",
    "                        'title': self.kg.graph.nodes[paper]['title']\n",
    "                    })\n",
    "        return papers\n",
    "\n",
    "    def find_mutual_citations(self):\n",
    "        \"\"\"Find pairs of authors who cite each other's work\"\"\"\n",
    "        mutual_citations = []\n",
    "\n",
    "        # Get all author pairs\n",
    "        authors = [n for n in self.kg.graph.nodes()\n",
    "                  if self.kg.graph.nodes[n].get('type') == 'author']\n",
    "\n",
    "        for i, author1 in enumerate(authors):\n",
    "            for author2 in authors[i+1:]:\n",
    "                # Get papers by each author\n",
    "                papers1 = {n for n in self.kg.graph.neighbors(author1)\n",
    "                          if self.kg.graph.nodes[n].get('type') == 'paper'}\n",
    "                papers2 = {n for n in self.kg.graph.neighbors(author2)\n",
    "                          if self.kg.graph.nodes[n].get('type') == 'paper'}\n",
    "\n",
    "                # Check if author1's papers cite author2's papers\n",
    "                cites_12 = any(\n",
    "                    cited in papers2\n",
    "                    for paper1 in papers1\n",
    "                    for cited in self.kg.graph.neighbors(paper1)\n",
    "                    if self.kg.graph[paper1][cited].get(0, {}).get('relation') == 'cites'\n",
    "                )\n",
    "\n",
    "                # Check if author2's papers cite author1's papers\n",
    "                cites_21 = any(\n",
    "                    cited in papers1\n",
    "                    for paper2 in papers2\n",
    "                    for cited in self.kg.graph.neighbors(paper2)\n",
    "                    if self.kg.graph[paper2][cited].get(0, {}).get('relation') == 'cites'\n",
    "                )\n",
    "\n",
    "                if cites_12 and cites_21:\n",
    "                    mutual_citations.append((\n",
    "                        self.kg.graph.nodes[author1]['name'],\n",
    "                        self.kg.graph.nodes[author2]['name']\n",
    "                    ))\n",
    "\n",
    "        return mutual_citations\n",
    "\n",
    "    def recommend_papers(self, paper_id, n=3):\n",
    "        \"\"\"Recommend papers based on topic similarity and citations\"\"\"\n",
    "        if paper_id not in self.kg.graph:\n",
    "            return []\n",
    "\n",
    "        # Get topics of the input paper\n",
    "        paper_topics = set()\n",
    "        for neighbor in self.kg.graph.neighbors(paper_id):\n",
    "            if self.kg.graph.nodes[neighbor].get('type') == 'topic':\n",
    "                paper_topics.add(neighbor)\n",
    "\n",
    "        # Score other papers based on shared topics\n",
    "        scores = defaultdict(int)\n",
    "        for paper in self.kg.graph.nodes():\n",
    "            if (self.kg.graph.nodes[paper].get('type') == 'paper'\n",
    "                and paper != paper_id):\n",
    "                # Topic similarity\n",
    "                for neighbor in self.kg.graph.neighbors(paper):\n",
    "                    if neighbor in paper_topics:\n",
    "                        scores[paper] += 2\n",
    "\n",
    "                # Citation relationship (bonus)\n",
    "                if self.kg.graph.has_edge(paper_id, paper):\n",
    "                    scores[paper] += 3\n",
    "                if self.kg.graph.has_edge(paper, paper_id):\n",
    "                    scores[paper] += 1\n",
    "\n",
    "        # Sort and return top N\n",
    "        top_papers = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "        return [{\n",
    "            'id': paper,\n",
    "            'title': self.kg.graph.nodes[paper]['title'],\n",
    "            'score': score\n",
    "        } for paper, score in top_papers]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e89bc8",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "Deriving new facts from existing facts\n",
    "\n",
    "**Inference is like Sudoku:**\n",
    "\n",
    "* The grid has some numbers (facts)\n",
    "* The rules say 'no duplicates in row/column'\n",
    "* You figure out missing numbers (inference)\n",
    "* You CREATE new knowledge using logic!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49cc9faf238d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-Based Inference\n",
    "\n",
    "class InferenceEngine:\n",
    "    def __init__(self, kg):\n",
    "        self.kg = kg\n",
    "        self.rules = []\n",
    "        self.derived_facts = set()\n",
    "\n",
    "    def add_rule(self, name, condition, action):\n",
    "        \"\"\"Add an inference rule\"\"\"\n",
    "        self.rules.append({\n",
    "            'name': name,\n",
    "            'condition': condition,\n",
    "            'action': action\n",
    "        })\n",
    "\n",
    "    def apply_rules(self):\n",
    "        \"\"\"Apply all rules to derive new knowledge\"\"\"\n",
    "        self.derived_facts.clear()\n",
    "\n",
    "        for rule in self.rules:\n",
    "            # Apply condition to find matches\n",
    "            matches = rule['condition'](self.kg)\n",
    "\n",
    "            # Apply action for each match\n",
    "            for match in matches:\n",
    "                fact = rule['action'](match)\n",
    "                self.derived_facts.add(fact)\n",
    "                print(f\"✓ Derived: {fact}\")\n",
    "\n",
    "        return self.derived_facts\n",
    "\n",
    "    def get_experts(self):\n",
    "        \"\"\"Find experts (authors with 3+ papers on a topic)\"\"\"\n",
    "        experts = []\n",
    "        authors = [n for n in self.kg.graph.nodes()\n",
    "                  if self.kg.graph.nodes[n].get('type') == 'author']\n",
    "\n",
    "        for author in authors:\n",
    "            # Get all papers by this author\n",
    "            papers = [n for n in self.kg.graph.neighbors(author)\n",
    "                     if self.kg.graph.nodes[n].get('type') == 'paper']\n",
    "\n",
    "            # Count papers per topic\n",
    "            topic_counts = defaultdict(int)\n",
    "            for paper in papers:\n",
    "                for topic in self.kg.graph.neighbors(paper):\n",
    "                    if self.kg.graph.nodes[topic].get('type') == 'topic':\n",
    "                        topic_counts[topic] += 1\n",
    "\n",
    "            # Find topics with 3+ papers\n",
    "            for topic, count in topic_counts.items():\n",
    "                if count >= 3:\n",
    "                    experts.append({\n",
    "                        'author': self.kg.graph.nodes[author]['name'],\n",
    "                        'topic': topic,\n",
    "                        'paper_count': count\n",
    "                    })\n",
    "\n",
    "        return experts\n",
    "\n",
    "    def find_trending_topics(self, min_recent_papers=3, recent_years=2):\n",
    "        \"\"\"Find trending topics (5+ papers in recent years)\"\"\"\n",
    "        current_year = 2024\n",
    "        trending = defaultdict(int)\n",
    "\n",
    "        for node in self.kg.graph.nodes():\n",
    "            if self.kg.graph.nodes[node].get('type') == 'paper':\n",
    "                year = self.kg.graph.nodes[node].get('year', 0)\n",
    "                if year >= current_year - recent_years:\n",
    "                    # Count topics\n",
    "                    for topic in self.kg.graph.neighbors(node):\n",
    "                        if self.kg.graph.nodes[topic].get('type') == 'topic':\n",
    "                            trending[topic] += 1\n",
    "\n",
    "        return [(topic, count) for topic, count in trending.items()\n",
    "                if count >= min_recent_papers]\n",
    "\n",
    "    def find_influential_papers(self, min_citations=3):\n",
    "        \"\"\"Find influential papers (highly cited)\"\"\"\n",
    "        influential = []\n",
    "\n",
    "        for node in self.kg.graph.nodes():\n",
    "            if self.kg.graph.nodes[node].get('type') == 'paper':\n",
    "                # Count incoming citations\n",
    "                citation_count = sum(\n",
    "                    1 for pred in self.kg.graph.predecessors(node)\n",
    "                    if self.kg.graph.nodes[pred].get('type') == 'paper'\n",
    "                    and self.kg.graph[pred][node].get(0, {}).get('relation') == 'cites'\n",
    "                )\n",
    "\n",
    "                if citation_count >= min_citations:\n",
    "                    influential.append({\n",
    "                        'id': node,\n",
    "                        'title': self.kg.graph.nodes[node]['title'],\n",
    "                        'citations': citation_count\n",
    "                    })\n",
    "\n",
    "        return sorted(influential, key=lambda x: x['citations'], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cbe124196f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_knowledge_graph():\n",
    "    \"\"\"Create a sample KG for demonstration\"\"\"\n",
    "    kg = AcademicKnowledgeGraph()\n",
    "\n",
    "    # Add authors\n",
    "    kg.add_author('a1', 'Alice Chen', 'MIT')\n",
    "    kg.add_author('a2', 'Bob Smith', 'Stanford')\n",
    "    kg.add_author('a3', 'Carol Wang', 'Berkeley')\n",
    "    kg.add_author('a4', 'David Lee', 'CMU')\n",
    "\n",
    "    # Add papers\n",
    "    kg.add_paper('p1', 'Deep Learning for NLP', 2022, ['NLP', 'Deep Learning'])\n",
    "    kg.add_paper('p2', 'Transformer Architecture Survey', 2023, ['NLP', 'Transformers'])\n",
    "    kg.add_paper('p3', 'Vision Transformers', 2023, ['Computer Vision', 'Transformers'])\n",
    "    kg.add_paper('p4', 'Graph Neural Networks', 2022, ['Deep Learning', 'Graph Learning'])\n",
    "    kg.add_paper('p5', 'Knowledge Graphs in AI', 2024, ['Knowledge Representation', 'AI'])\n",
    "    kg.add_paper('p6', 'Attention Mechanisms', 2023, ['Deep Learning', 'NLP'])\n",
    "    kg.add_paper('p7', 'Semantic Reasoning', 2024, ['Knowledge Representation', 'Reasoning'])\n",
    "\n",
    "    # Add authorships\n",
    "    kg.add_authorship('a1', 'p1')\n",
    "    kg.add_authorship('a1', 'p2')\n",
    "    kg.add_authorship('a1', 'p6')\n",
    "\n",
    "    kg.add_authorship('a2', 'p3')\n",
    "    kg.add_authorship('a2', 'p4')\n",
    "\n",
    "    kg.add_authorship('a3', 'p5')\n",
    "    kg.add_authorship('a3', 'p7')\n",
    "    kg.add_authorship('a1', 'p7')  # Alice and Carol coauthor\n",
    "\n",
    "    kg.add_authorship('a4', 'p4')\n",
    "    kg.add_authorship('a4', 'p6')\n",
    "\n",
    "    # Add citations\n",
    "    kg.add_citation('p2', 'p1')  # p2 cites p1\n",
    "    kg.add_citation('p3', 'p2')\n",
    "    kg.add_citation('p6', 'p1')\n",
    "    kg.add_citation('p6', 'p2')\n",
    "    kg.add_citation('p7', 'p5')\n",
    "    kg.add_citation('p5', 'p7')  # Mutual citation between Carol's papers\n",
    "\n",
    "    return kg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2408fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build Knowlege Graph\n",
    "print(\"=\" * 70)\n",
    "print(\"KNOWLEDGE REPRESENTATION GRAPH SIMULATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n PHASE 1: Building Knowledge Graph...\")\n",
    "kg = create_sample_knowledge_graph()\n",
    "print(f\" Created graph with {kg.graph.number_of_nodes()} nodes and {kg.graph.number_of_edges()} edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7120d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Semantic Queries\n",
    "print(\"\\n PHASE 2: Semantic Queries...\")\n",
    "query_engine = QueryEngine(kg)\n",
    "\n",
    "print(\"\\n1. Papers by Alice Chen:\")\n",
    "papers = query_engine.get_papers_by_author('a1')\n",
    "for p in papers:\n",
    "    print(f\"   • {p['title']} ({p['year']})\")\n",
    "\n",
    "print(\"\\n2. Alice Chen's coauthors:\")\n",
    "coauthors = query_engine.find_coauthors('a1')\n",
    "for author in coauthors:\n",
    "    print(f\"   • {kg.graph.nodes[author]['name']}\")\n",
    "\n",
    "print(\"\\n3. Papers on 'NLP':\")\n",
    "nlp_papers = query_engine.find_papers_on_topic('NLP')\n",
    "for p in nlp_papers:\n",
    "    print(f\"   • {p['title']}\")\n",
    "\n",
    "print(\"\\n4. Authors with mutual citations:\")\n",
    "mutual = query_engine.find_mutual_citations()\n",
    "for a1, a2 in mutual:\n",
    "    print(f\"   • {a1} ↔ {a2}\")\n",
    "\n",
    "print(\"\\n5. Recommendations for 'Deep Learning for NLP':\")\n",
    "recs = query_engine.recommend_papers('p1', n=3)\n",
    "for rec in recs:\n",
    "    print(f\"   • {rec['title']} (score: {rec['score']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe660ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rule-Based Inference\n",
    "print(\"\\n PHASE 3: Rule-Based Inference...\")\n",
    "inference = InferenceEngine(kg)\n",
    "\n",
    "print(\"\\n1. Experts (3+ papers on a topic):\")\n",
    "experts = inference.get_experts()\n",
    "for exp in experts:\n",
    "    print(f\"   • {exp['author']} is an expert in '{exp['topic']}' ({exp['paper_count']} papers)\")\n",
    "\n",
    "print(\"\\n2. Trending topics (3+ recent papers):\")\n",
    "trending = inference.find_trending_topics(min_recent_papers=2, recent_years=2)\n",
    "for topic, count in trending:\n",
    "    print(f\"   • {topic}: {count} recent papers\")\n",
    "\n",
    "print(\"\\n3. Influential papers (3+ citations):\")\n",
    "influential = inference.find_influential_papers(min_citations=2)\n",
    "for paper in influential:\n",
    "    print(f\"   • {paper['title']} ({paper['citations']} citations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_kg(kg, figsize=(16, 12), show_edge_labels=True):\n",
    "    \"\"\"Visualize the knowledge graph with clear directed edges\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    pos = nx.spring_layout(kg.graph, k=2.5, iterations=50, seed=42)\n",
    "    \n",
    "    # Color nodes by type\n",
    "    node_colors = []\n",
    "    node_sizes = []\n",
    "    for node in kg.graph.nodes():\n",
    "        node_type = kg.graph.nodes[node].get('type', 'unknown')\n",
    "        if node_type == 'paper':\n",
    "            node_colors.append('#3498db')  # Blue\n",
    "            node_sizes.append(1200)\n",
    "        elif node_type == 'author':\n",
    "            node_colors.append('#e74c3c')  # Red\n",
    "            node_sizes.append(1500)\n",
    "        elif node_type == 'topic':\n",
    "            node_colors.append('#2ecc71')  # Green\n",
    "            node_sizes.append(1000)\n",
    "        else:\n",
    "            node_colors.append('#95a5a6')  # Gray\n",
    "            node_sizes.append(800)\n",
    "    \n",
    "    # Draw nodes with better styling\n",
    "    nx.draw_networkx_nodes(kg.graph, pos, \n",
    "                          node_color=node_colors, \n",
    "                          node_size=node_sizes,\n",
    "                          alpha=0.9,\n",
    "                          edgecolors='black',\n",
    "                          linewidths=2)\n",
    "    \n",
    "    # Draw node labels\n",
    "    nx.draw_networkx_labels(kg.graph, pos, font_size=9, font_weight='bold')\n",
    "    \n",
    "    # Group edges by relationship type for different colors\n",
    "    edge_colors = {\n",
    "        'authored': '#e74c3c',      # Red\n",
    "        'written_by': '#e74c3c',    # Red\n",
    "        'cites': '#9b59b6',         # Purple\n",
    "        'cited_by': '#9b59b6',      # Purple\n",
    "        'has_topic': '#2ecc71',     # Green\n",
    "    }\n",
    "    \n",
    "    # Draw edges grouped by type with different colors\n",
    "    for relation_type, color in edge_colors.items():\n",
    "        edges_of_type = [\n",
    "            (u, v) for u, v, key, data in kg.graph.edges(keys=True, data=True)\n",
    "            if data.get('relation') == relation_type\n",
    "        ]\n",
    "        if edges_of_type:\n",
    "            nx.draw_networkx_edges(\n",
    "                kg.graph, pos,\n",
    "                edgelist=edges_of_type,\n",
    "                edge_color=color,\n",
    "                arrows=True,\n",
    "                arrowsize=20,           # Larger arrows\n",
    "                arrowstyle='-|>',       # Clear arrow style\n",
    "                width=2.5,              # Thicker edges\n",
    "                alpha=0.7,\n",
    "                connectionstyle='arc3,rad=0.1',  # Curved edges\n",
    "                node_size=node_sizes[0] if node_sizes else 1000\n",
    "            )\n",
    "    \n",
    "    # Add edge labels if requested\n",
    "    if show_edge_labels:\n",
    "        edge_labels = {}\n",
    "        for u, v, key, data in kg.graph.edges(keys=True, data=True):\n",
    "            relation = data.get('relation', '')\n",
    "            if relation:\n",
    "                # Only show one label per edge pair to avoid clutter\n",
    "                if (u, v) not in edge_labels:\n",
    "                    edge_labels[(u, v)] = relation\n",
    "        \n",
    "        nx.draw_networkx_edge_labels(\n",
    "            kg.graph, pos,\n",
    "            edge_labels=edge_labels,\n",
    "            font_size=7,\n",
    "            font_color='darkblue',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.6)\n",
    "        )\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#e74c3c', label='Author', edgecolor='black'),\n",
    "        Patch(facecolor='#3498db', label='Paper', edgecolor='black'),\n",
    "        Patch(facecolor='#2ecc71', label='Topic', edgecolor='black'),\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='upper left', fontsize=12)\n",
    "    \n",
    "    plt.title(\"Academic Knowledge Graph (Directed)\", fontsize=18, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_subgraph(kg, central_node, depth=1, figsize=(12, 10)):\n",
    "    \"\"\"Visualize a subgraph around a specific node for clearer directed edges\"\"\"\n",
    "    # Get nodes within 'depth' hops from central_node\n",
    "    nodes_to_include = {central_node}\n",
    "    current_layer = {central_node}\n",
    "    \n",
    "    for _ in range(depth):\n",
    "        next_layer = set()\n",
    "        for node in current_layer:\n",
    "            # Get both predecessors and successors\n",
    "            next_layer.update(kg.graph.predecessors(node))\n",
    "            next_layer.update(kg.graph.successors(node))\n",
    "        nodes_to_include.update(next_layer)\n",
    "        current_layer = next_layer\n",
    "    \n",
    "    # Create subgraph\n",
    "    subgraph = kg.graph.subgraph(nodes_to_include).copy()\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    pos = nx.spring_layout(subgraph, k=2, iterations=50, seed=42)\n",
    "    \n",
    "    # Color nodes\n",
    "    node_colors = []\n",
    "    node_sizes = []\n",
    "    for node in subgraph.nodes():\n",
    "        node_type = subgraph.nodes[node].get('type', 'unknown')\n",
    "        if node == central_node:\n",
    "            node_colors.append('#f39c12')  # Orange for central node\n",
    "            node_sizes.append(2000)\n",
    "        elif node_type == 'paper':\n",
    "            node_colors.append('#3498db')\n",
    "            node_sizes.append(1200)\n",
    "        elif node_type == 'author':\n",
    "            node_colors.append('#e74c3c')\n",
    "            node_sizes.append(1500)\n",
    "        elif node_type == 'topic':\n",
    "            node_colors.append('#2ecc71')\n",
    "            node_sizes.append(1000)\n",
    "        else:\n",
    "            node_colors.append('#95a5a6')\n",
    "            node_sizes.append(800)\n",
    "    \n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(subgraph, pos,\n",
    "                          node_color=node_colors,\n",
    "                          node_size=node_sizes,\n",
    "                          alpha=0.9,\n",
    "                          edgecolors='black',\n",
    "                          linewidths=2)\n",
    "    \n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(subgraph, pos, font_size=10, font_weight='bold')\n",
    "    \n",
    "    # Draw edges with clear arrows\n",
    "    edge_colors_map = {\n",
    "        'authored': '#e74c3c',\n",
    "        'written_by': '#e74c3c',\n",
    "        'cites': '#9b59b6',\n",
    "        'cited_by': '#9b59b6',\n",
    "        'has_topic': '#2ecc71',\n",
    "    }\n",
    "    \n",
    "    for relation_type, color in edge_colors_map.items():\n",
    "        edges_of_type = [\n",
    "            (u, v) for u, v, key, data in subgraph.edges(keys=True, data=True)\n",
    "            if data.get('relation') == relation_type\n",
    "        ]\n",
    "        if edges_of_type:\n",
    "            nx.draw_networkx_edges(\n",
    "                subgraph, pos,\n",
    "                edgelist=edges_of_type,\n",
    "                edge_color=color,\n",
    "                arrows=True,\n",
    "                arrowsize=25,\n",
    "                arrowstyle='-|>',\n",
    "                width=3,\n",
    "                alpha=0.8,\n",
    "                connectionstyle='arc3,rad=0.15',\n",
    "                node_size=node_sizes[0] if node_sizes else 1000\n",
    "            )\n",
    "    \n",
    "    # Add edge labels\n",
    "    edge_labels = {}\n",
    "    for u, v, key, data in subgraph.edges(keys=True, data=True):\n",
    "        relation = data.get('relation', '')\n",
    "        if relation and (u, v) not in edge_labels:\n",
    "            edge_labels[(u, v)] = relation\n",
    "    \n",
    "    nx.draw_networkx_edge_labels(\n",
    "        subgraph, pos,\n",
    "        edge_labels=edge_labels,\n",
    "        font_size=9,\n",
    "        font_color='darkblue',\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7)\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Subgraph around '{central_node}' (depth={depth})\", \n",
    "             fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Visualizing full knowledge graph...\")\n",
    "visualize_kg(kg, show_edge_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Visualizing subgraph around 'a3'...\")\n",
    "visualize_subgraph(kg, 'a3', depth=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
